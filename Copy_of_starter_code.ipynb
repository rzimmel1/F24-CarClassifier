{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rzimmel1/F24-CarClassifier/blob/main/Copy_of_starter_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzMqROcf5ofz",
        "outputId": "0d566524-dd7f-4d1c-ab8a-aa5e2356b5a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.5.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.0->torchvision) (3.0.2)\n",
            "Collecting torch.optim\n",
            "  Downloading torch_optim-0.0.4-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting deap>=1.3.1 (from torch.optim)\n",
            "  Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting pytorch-ignite>=0.4.8 (from torch.optim)\n",
            "  Downloading pytorch_ignite-0.5.1-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting thop>=0.0.31 (from torch.optim)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torch.optim) (2.5.0+cu121)\n",
            "Collecting torch-pruning>=0.2.7 (from torch.optim)\n",
            "  Downloading torch_pruning-1.4.3-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: torchvision>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from torch.optim) (0.20.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deap>=1.3.1->torch.optim) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytorch-ignite>=0.4.8->torch.optim) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torch.optim) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torch.optim) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torch.optim) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torch.optim) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torch.optim) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torch.optim) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->torch.optim) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.11.1->torch.optim) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torch.optim) (3.0.2)\n",
            "Downloading torch_optim-0.0.4-py3-none-any.whl (59.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_ignite-0.5.1-py3-none-any.whl (312 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.7/312.7 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading torch_pruning-1.4.3-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.9/62.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deap, torch-pruning, thop, pytorch-ignite, torch.optim\n",
            "Successfully installed deap-1.4.1 pytorch-ignite-0.5.1 thop-0.1.1.post2209072238 torch-pruning-1.4.3 torch.optim-0.0.4\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch.utils.data (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch.utils.data\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision.transforms (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchvision.transforms\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement PIL (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for PIL\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#These are pip install commands, which will download all the libraries and tools you'll need for this project.\n",
        "#Once you've installed these, you shouldn't have to keep re-running this cell.\n",
        "!pip install kaggle\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install os\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install torch.optim\n",
        "!pip install torch.utils.data\n",
        "!pip install torchvision.transforms\n",
        "!pip install PIL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Connect to your Google account that has your Kaggle API in your Drive.\n",
        "!pip install kaggle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#These are the imports you will need for this project. If you find a tool from another library you want to use, you can import here.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import time\n",
        "import copy"
      ],
      "metadata": {
        "id": "W9a-FOXs4H9q",
        "outputId": "652eb3a5-3090-425a-8398-ffb786620568",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set up your Kaggle account and add the JSON file into your Google Drive.\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/MyDrive/kaggle.json\"\n",
        "#We're downloading our modified brand dataset and unzipping it into our directory.\n",
        "!kaggle datasets download -d aditikashi/stanford-car-dataset-brands-only-csv-files\n",
        "!unzip stanford-car-dataset-brands-only-csv-files.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpckFvoh5wzx",
        "outputId": "4ae6217f-eec4-45f0-f26f-20d476dda18d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/aditikashi/stanford-car-dataset-brands-only-csv-files\n",
            "License(s): apache-2.0\n",
            "stanford-car-dataset-brands-only-csv-files.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  stanford-car-dataset-brands-only-csv-files.zip\n",
            "replace cardata/cars_annos.mat? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00001.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00002.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00003.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00004.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00005.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
            "error:  invalid response [{ENTER}]\n",
            "replace cardata/cars_test/cars_test/00005.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00006.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00007.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00008.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00009.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00010.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00011.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00012.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00013.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00014.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00015.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00016.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00017.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00018.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00019.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00020.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00021.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00022.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00023.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00024.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00025.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00026.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00027.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00028.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00029.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00030.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00031.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00032.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00033.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00034.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00035.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00036.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00037.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00038.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00039.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00040.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00041.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00042.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00043.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00044.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00045.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00046.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00047.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00048.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00049.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00050.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00051.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00052.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00053.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00054.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00055.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cardata/cars_test/cars_test/00056.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This line specify the paths to the CSV file and the image folder. Do NOT edit this, since it matches the imported dataset.\n",
        "PATH = \"cardata/\"\n",
        "\n",
        "#Create two pandas DataFrames that hold the info in the CSV files.\n",
        "train_df = pd.read_csv(f'{PATH}train.csv')\n",
        "test_df = pd.read_csv(f'{PATH}test.csv')\n",
        "\n",
        "# Let's inspect the data!\n",
        "print(\"Training Dataset:\\n\", train_df.head())\n",
        "print(\"Testing Dataset:\\n\", test_df.head())\n",
        "\n",
        "# Step 2: Check the distribution of car brands, a.k.a how many images of each brand there are.\n",
        "print(\"\\nCar brand distribution in training dataset:\\n\", train_df['label'].value_counts())\n",
        "print(\"\\nCar brand distribution in testing dataset:\\n\", test_df['label'].value_counts())\n",
        "\n",
        "# Step 3: Take a random sampling of data. The reason we do this is because Jupyter Notebook can't efficiently run all 8000 training and 8000 testing images, so we have to\n",
        "#have a smaller data set that can be run here. Don't worry about the semantics of this code, but all it's doing is taking 3000 sample images from each dataset. You can\n",
        "#change the number 3000 to a different number if you'd like to test it out. We do this process for both training and testing data.\n",
        "train_sampled_df = train_df.groupby('label').apply(lambda x: x.sample(min(len(x), 3000 // train_df['label'].nunique()))).reset_index(drop=True)\n",
        "test_sampled_df = test_df.groupby('label').apply(lambda x: x.sample(min(len(x), 3000 // test_df['label'].nunique()))).reset_index(drop=True)\n",
        "\n",
        "# Step 4: We can save these new datasets to new CSV files, new_train and new_test. The reason we made new files is in case we want to reaccess all of the data at any point.\n",
        "#For model development, you'll be using these new CSV files.\n",
        "train_sampled_df.to_csv('/content/cardata/new_train.csv', index=False)\n",
        "test_sampled_df.to_csv('/content/cardata/new_test.csv', index=False)\n",
        "\n",
        "#Let's inspect the size of the new datasets!\n",
        "print(\"New Training Dataset shape:\", train_sampled_df.shape)\n",
        "print(\"New Testing Dataset shape:\", test_sampled_df.shape)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKA60UzvAfN0",
        "outputId": "9c4b9e16-6e5d-4e73-a468-03c91654b947"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset:\n",
            "    imagename    label\n",
            "0  00001.jpg     Audi\n",
            "1  00002.jpg    Acura\n",
            "2  00003.jpg    Dodge\n",
            "3  00004.jpg  Hyundai\n",
            "4  00005.jpg     Ford\n",
            "Testing Dataset:\n",
            "    imagename    label\n",
            "0  00001.jpg   Suzuki\n",
            "1  00002.jpg  Ferrari\n",
            "2  00003.jpg     Jeep\n",
            "3  00004.jpg   Toyota\n",
            "4  00005.jpg    Tesla\n",
            "\n",
            "Car brand distribution in training dataset:\n",
            " label\n",
            "Chevrolet        905\n",
            "Dodge            630\n",
            "Audi             589\n",
            "BMW              531\n",
            "Ford             521\n",
            "Hyundai          438\n",
            "Mercedes-Benz    261\n",
            "Chrysler         260\n",
            "Acura            242\n",
            "GMC              238\n",
            "Bentley          238\n",
            "Jeep             220\n",
            "Nissan           171\n",
            "Toyota           168\n",
            "Suzuki           167\n",
            "Ferrari          164\n",
            "Honda            161\n",
            "Lamborghini      161\n",
            "Buick            158\n",
            "Aston            157\n",
            "Volkswagen       132\n",
            "Volvo            131\n",
            "Cadillac         129\n",
            "Rolls-Royce      114\n",
            "Spyker            88\n",
            "Land              86\n",
            "HUMMER            83\n",
            "Bugatti           77\n",
            "Infiniti          67\n",
            "FIAT              62\n",
            "Mitsubishi        48\n",
            "Jaguar            47\n",
            "Eagle             46\n",
            "Daewoo            45\n",
            "Geo               45\n",
            "AM                45\n",
            "McLaren           44\n",
            "Porsche           44\n",
            "Fisker            44\n",
            "Plymouth          44\n",
            "Scion             42\n",
            "Ram               41\n",
            "smart             40\n",
            "Isuzu             40\n",
            "Tesla             39\n",
            "Lincoln           39\n",
            "MINI              37\n",
            "Mazda             36\n",
            "Maybach           29\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Car brand distribution in testing dataset:\n",
            " label\n",
            "Chevrolet        894\n",
            "Dodge            623\n",
            "Audi             580\n",
            "BMW              524\n",
            "Ford             514\n",
            "Hyundai          433\n",
            "Mercedes-Benz    257\n",
            "Chrysler         256\n",
            "Acura            240\n",
            "GMC              235\n",
            "Bentley          234\n",
            "Jeep             218\n",
            "Nissan           170\n",
            "Suzuki           166\n",
            "Toyota           164\n",
            "Ferrari          162\n",
            "Honda            160\n",
            "Lamborghini      158\n",
            "Aston            157\n",
            "Buick            156\n",
            "Volkswagen       131\n",
            "Volvo            129\n",
            "Cadillac         128\n",
            "Rolls-Royce      112\n",
            "Spyker            87\n",
            "Land              84\n",
            "HUMMER            82\n",
            "Bugatti           75\n",
            "Infiniti          66\n",
            "FIAT              60\n",
            "Mitsubishi        47\n",
            "Jaguar            46\n",
            "Eagle             46\n",
            "Daewoo            45\n",
            "AM                44\n",
            "Plymouth          44\n",
            "McLaren           44\n",
            "Geo               44\n",
            "Fisker            43\n",
            "Porsche           43\n",
            "Scion             41\n",
            "Ram               41\n",
            "Isuzu             40\n",
            "smart             40\n",
            "Lincoln           39\n",
            "Tesla             38\n",
            "Mazda             36\n",
            "MINI              36\n",
            "Maybach           29\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-308a482284cd>:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  train_sampled_df = train_df.groupby('label').apply(lambda x: x.sample(min(len(x), 3000 // train_df['label'].nunique()))).reset_index(drop=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Training Dataset shape: (2625, 2)\n",
            "New Testing Dataset shape: (2615, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-308a482284cd>:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  test_sampled_df = test_df.groupby('label').apply(lambda x: x.sample(min(len(x), 3000 // test_df['label'].nunique()))).reset_index(drop=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Okay, now it's time to work on our model! We've given you some of the basic code and function structure you'll need.\n",
        "#This first section of code essentially reads, writes, and accesses our data. Don't worry about the functionality.\n",
        "class CustomCarDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        #The three values below this comment are important!!\n",
        "        self.labels_df = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        #Get a list of all the unique car brands for the classes.\n",
        "        self.classes = self.labels_df['label'].unique().tolist()\n",
        "        #Maps the labels to the indices.\n",
        "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #Get the image file name and label from the dataframe.\n",
        "        img_name = os.path.join(self.img_dir, self.labels_df.iloc[idx, 0])\n",
        "        #Open the image and convert to RGB.\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "\n",
        "        #Get the corresponding label and map it to the index\n",
        "        label = self.class_to_idx[self.labels_df.iloc[idx, 1]]\n",
        "\n",
        "        #Apply the transformations you created.\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "#This is where you'll add your image augmentation. Refer back to the image augmentation notebook for some guidance.\n",
        "#One function you'll definitely need is transforms.CenterCrop(). This is because the ResNet-50 model only uses images\n",
        "#with inputs of size 244 by 244 (hint!). Another function you'll need is transforms.ToTensor(), since Tensorflow will only process data\n",
        "#that is in tensor form. Finally, transforms.Normalize() is a way to standardize the images using ImageNet, which is typical\n",
        "#for any models that were pre-trained using ImageNet, like ResNet50! Essentially, ResNet was originally trained on the images\n",
        "#in ImageNet, so we adjust the range of our pixel values to match the range used in the ImageNet dataset.\n",
        "\n",
        "#We've given you some of the functions you'll need, so it's your job to go through documentation and test out some code.\n",
        "\n",
        "#TO-DO: Add the necessary functions we mentioned, and experiment with more image augmentation techniques that change more aspects of the images.\n",
        "#Again, refer back to the image augmentation notebook for this. Try to see what combinations can increase your accuracy.\n",
        "data_transforms = transforms.Compose([\n",
        "       transforms.CenterCrop(244),\n",
        "       transforms.ToTensor(),\n",
        "       transforms.Normalize(mean=[0.485, 0.456, 0.406], std =[0.229,0.224,0.225] ,inplace=False)\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#These are file paths for the CSV and the image directories.\n",
        "train_img_dir = '/content/cardata/cars_train/cars_train'\n",
        "train_csv = '/content/cardata/new_train.csv'\n",
        "\n",
        "test_img_dir = '/content/cardata/cars_test/cars_test'\n",
        "test_csv = '/content/cardata/new_test.csv'\n",
        "\n",
        "#TO-DO: Create Dataset() instances here for the training and testing. Look at the def_init function at the very\n",
        "#beginning that we have provided for you. Think about how you could call this class (CustomCardataset()) and what input values\n",
        "#you might need to use. Hint: since this is a class, it won't be exactly like calling a function\n",
        "train_dataset = CustomCarDataset(csv_file=train_csv, img_dir=train_img_dir, transform=data_transforms)\n",
        "test_dataset = CustomCarDataset(csv_file=test_csv, img_dir=test_img_dir, transform=data_transforms)\n",
        "\n",
        "#TO-DO: Create DataLoader() instances here for the training and testing. Documentation is your friend! Search for\n",
        "#DataLoader documentation, and experiment with the parameters you give the function.\n",
        "train_loader = DataLoader(train_dataset)\n",
        "test_loader = DataLoader(test_dataset)\n",
        "\n",
        "# Prepare dataloaders and dataset sizes for the training and testing phases.\n",
        "dataloaders = {\n",
        "    'train': train_loader,\n",
        "    'test': test_loader,\n",
        "}\n",
        "\n",
        "dataset_sizes = {\n",
        "    'train': len(train_dataset),\n",
        "    'test': len(test_dataset),\n",
        "}\n",
        "\n",
        "#Get the class names (car brands) and the number of car brands.\n",
        "class_names = train_dataset.classes\n",
        "num_classes = len(class_names)\n",
        "\n",
        "#Check if we can use torch.cuda for fast implementaiton or CPU.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#Here's where you'll be implementing your model. Again, documentation, Google, and ChatGPT is your friend.\n",
        "#We'll leave in variable names so you have a general idea of what to follow and so that the code flows with the\n",
        "#pre-written aspects.\n",
        "\n",
        "#Here is where you set the model to ResNet-50. Look at some of the parameters you might need.\n",
        "model_ft = models.resnet50(pretrained=True)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#Here is where you will add some of the features of the model, like the loss function, optimizer, and learning\n",
        "#rate scheduler. You can use whatever features you'd like, and keep experimenting with different hyperparameters to\n",
        "#see what works best. Once again, look at documentation!\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = torch.optim.Adam(model_ft.parameters(), lr=0.001)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\n",
        "#Modify the fully connected layer to match the number of car brands (hint: where did we get the number of car brands?).\n",
        "model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "#This section of the code creates the training and testing pipeline. While this is an important part of the computer vision\n",
        "#pipeline, it mainly involves iterating over data and finding accuracy, which are not as critical to your fundamental\n",
        "#understanding of computer vision as a whole. We've given you the code that will iterate through your model. Feel free to change\n",
        "#or add anything you'd like (hint: you can look into things like freezing a layer, adding a layer, etc).\n",
        "\n",
        "#TO-DO: Experiment as much as you'd like with adding layers, freezing layers, anything you'd like to try.\n",
        "#We'll go over some features you can add to make your model better in future sessions, but feel free to try stuff out yourself.\n",
        "def make_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "\n",
        "    since = time.time()\n",
        "\n",
        "    #Save the best model and best accuracy.\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        #Each epoch has a training and validation phase.\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                #Set the model to training mode.\n",
        "                model.train()\n",
        "            else:\n",
        "                #Set the model to testing mode.\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            #Iterate over all the data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                #Zero the parameter gradients.\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                #TO-DO: This is a place where you could add more features, like cross-validation, freezing, etc.\n",
        "\n",
        "                #Forward pass: run through the model forwards.\n",
        "                #Only track the history of the model if it's in train mode.\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    #Backward pass + optimize: this only happens while in train mode.\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                #Calculate running loss function and the number of correct guesses.\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            #Make a deep copy of the best model and update accuracy.\n",
        "            if phase == 'test' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    #Check how much time training took.\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best test Acc: {best_acc:.4f}')\n",
        "\n",
        "    #Load the best model weights for the next epoch.\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "#Write this function that calls the training function with all its parameters.\n",
        "model_ft = make_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)\n",
        " #would be changin num epochs\n",
        "\n",
        "#Save the best model.\n",
        "torch.save(model_ft.state_dict(), 'car_brand_model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "sWD8ThFGAk54",
        "outputId": "72401945-a3b8-4737-ed47-3c4527386f81"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-a5172258ff02>\u001b[0m in \u001b[0;36m<cell line: 189>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;31m#Write this function that calls the training function with all its parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m \u001b[0mmodel_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m  \u001b[0;31m#would be changin num epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-a5172258ff02>\u001b[0m in \u001b[0;36mmake_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;31m#Only track the history of the model if it's in train mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \"\"\"\n\u001b[0;32m--> 193\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2810\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2812\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2813\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}